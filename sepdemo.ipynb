{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae2d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, sys\n",
    "import gradio as gr\n",
    "import soundfile as sf\n",
    "print(f\"Using torch {torch.__version__}\")\n",
    "print(f\"Using python {sys.version}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2814b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from nets.model_wrapper import SeparationModel\n",
    "from utils.audio_utils import resample\n",
    "from utils.average_model_params import average_model_params\n",
    "from utils.config import yaml_to_parser\n",
    "\n",
    "RESAMPLE_RATE = 48000\n",
    "\n",
    "# parameters used to plot the spectrogram\n",
    "n_fft = 512\n",
    "hop_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"pretrained_models/tuss.medium.2-4src/hparams.yaml\"\n",
    "ckpt_paths = [Path(\"pretrained_models/tuss.medium.2-4src/checkpoints/model.pth\")]\n",
    "# instantiate the model\n",
    "hparams = yaml_to_parser(config_path)\n",
    "hparams = hparams.parse_args([])\n",
    "model = SeparationModel(\n",
    "    hparams.encoder_name,\n",
    "    hparams.encoder_conf,\n",
    "    hparams.decoder_name,\n",
    "    hparams.decoder_conf,\n",
    "    hparams.model_name,\n",
    "    hparams.model_conf,\n",
    "    hparams.css_conf,\n",
    "    hparams.variance_normalization,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01456e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = average_model_params(ckpt_paths)\n",
    "new_state_dict = {}\n",
    "for key, value in state_dict.items():\n",
    "    k = key.replace(\"model.\", \"\")\n",
    "    new_state_dict[k] = value\n",
    "model.load_state_dict(new_state_dict)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514cf176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(audio_path,prompts):\n",
    "  mix, fs = torchaudio.load(audio_path)\n",
    "  mix = mix[[0],:4*fs]\n",
    "  mix_return = mix.clone()\n",
    "  mix = mix.cuda()\n",
    "  if RESAMPLE_RATE != fs:\n",
    "    mix = resample(mix, fs, RESAMPLE_RATE)\n",
    "  with torch.no_grad():\n",
    "    y, *_ = model(mix, [prompts])\n",
    "  if RESAMPLE_RATE != fs:\n",
    "    y = resample(y, RESAMPLE_RATE, fs)\n",
    "  return y.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58392fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix, fs = torchaudio.load(\"mix.wav\")\n",
    "print(f'fs: {fs}, len: {len(mix[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34aa276",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = apply_model(\"mix.wav\", [\"speech\", \"sfxbg\", \"musicbg\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
